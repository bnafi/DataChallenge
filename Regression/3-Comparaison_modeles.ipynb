{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Démarches préliminaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.a- Importation des librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "#general librairies\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#sklearn librairies\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.ensemble import * \n",
    "from sklearn.svm import *\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "\n",
    "#appel a nos fonctions\n",
    "from fcts_R.general import * \n",
    "from fcts_R.dataset_division import *\n",
    "from fcts_R.combinaison import * \n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Traitement du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.read_csv(\"datasets_R/data0.csv\")\n",
    "data1 = pd.read_csv(\"datasets_R/data1.csv\")\n",
    "\n",
    "\n",
    "#On sépare les co-variables de la variable à prédire\n",
    "X0,y0 = treatment(data0)\n",
    "X1,y1 = treatment(data1)\n",
    "\n",
    "#Data0: \n",
    "X_tr0, X_te0, y_tr0, y_te0= train_test_split(X0,y0, test_size=0.33,random_state=2023)\n",
    "\n",
    "#Data1:\n",
    "X_tr1, X_te1, y_tr1, y_te1= train_test_split(X1,y1, test_size=0.33,random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Comparaison des performances des modèles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs modèles pour data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'mod': ExtraTreesRegressor(n_estimators=1000, random_state=50)}\n",
      "Best Score:  0.4453407130077863\n"
     ]
    }
   ],
   "source": [
    "models_0 = {'mod' : [NuSVR(C=1,gamma= 'scale', kernel='rbf',nu=0.6), xgb.XGBRFRegressor(random_state=50, n_estimators=150),ExtraTreesRegressor(random_state=50, max_samples=None, n_estimators=1000), BaggingRegressor(n_estimators= 2250, random_state=10)]}\n",
    "\n",
    "#On crée une pipeline\n",
    "pipe_0 = Pipeline(steps=[('std', StandardScaler()),('mod', LinearRegression())])\n",
    "\n",
    "#On cherche le meilleur modèle par cross-validation \n",
    "grid_search_0 = GridSearchCV(estimator=pipe_0,param_grid=models_0,cv=5)\n",
    "grid_search_0.fit(X_tr0, y_tr0.to_numpy().ravel())\n",
    "print(\"Best Hyperparameters: \", grid_search_0.best_params_)\n",
    "print(\"Best Score: \", grid_search_0.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meilleurs models pour data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'mod': ExtraTreesRegressor(n_estimators=2750, random_state=50)}\n",
      "Best Score:  0.44142366751757073\n"
     ]
    }
   ],
   "source": [
    "models_1 = {'mod': [NuSVR(kernel=\"rbf\", gamma=\"scale\", nu=0.5,C=1), xgb.XGBRFRegressor(seed=2023, n_estimators=415), ExtraTreesRegressor(n_estimators=2750,random_state=50, max_samples=None)]}\n",
    "\n",
    "#On crée une pipeline et on cherche le meilleur modèle par cross validation \n",
    "pipe_1 = Pipeline(steps=[('std', StandardScaler()),('mod', LinearRegression())])\n",
    "\n",
    "#On cherche par cross validation le meilleur modèle \n",
    "grid_search_1 = GridSearchCV(estimator=pipe_1,param_grid=models_1,cv=5)\n",
    "grid_search_1.fit(X_tr1, y_tr1.to_numpy().ravel())\n",
    "print(\"Best Hyperparameters: \", grid_search_1.best_params_)\n",
    "print(\"Best Score: \", grid_search_1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Choix de la meilleure combinaison  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_0 = np.array([NuSVR(C=1,gamma= 'scale', kernel='rbf',nu=0.6), xgb.XGBRFRegressor(random_state=50, n_estimators=150),ExtraTreesRegressor(random_state=50, max_samples=None, n_estimators=1000), BaggingRegressor(n_estimators= 2250, random_state=10)])\n",
    "mods_1 = np.array([NuSVR(kernel=\"rbf\", gamma=\"scale\", nu=0.5,C=1), xgb.XGBRFRegressor(seed=2023, n_estimators=415), ExtraTreesRegressor(n_estimators=2750,random_state=50, max_samples=None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choix des deux prédicteurs de base par cross-validation \n",
    "mod0, mod1 = choix_melange(mods_0, mods_1, data0, data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - On sauvegarde les modèles dans un fichier YAML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables sauvegardées dans modeles_choisis.yaml\n"
     ]
    }
   ],
   "source": [
    "data = {\"model0\": str(mod0),\"model1\": str(mod1)}\n",
    "yaml_file_path = \"modeles_choisis.yaml\"\n",
    "\n",
    "with open(yaml_file_path, \"w\") as yaml_file:\n",
    "    yaml.dump(data, yaml_file, default_flow_style=False)\n",
    "print(f\"Variables sauvegardées dans {yaml_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datachallenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
